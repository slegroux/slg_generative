# AUTOGENERATED! DO NOT EDIT! File to edit: ../nbs/02_training.ipynb.

# %% auto 0
__all__ = ['Trainer']

# %% ../nbs/02_training.ipynb 3
from .models.vae import AutoEncoder
from .data.datasets import FashionMnistDataset
from torch.utils.data import DataLoader
from torch.optim import Adam
import torch.nn as nn
from tqdm import tqdm
import torch

# %% ../nbs/02_training.ipynb 4
class Trainer:
    "Trainer for VAE models"

    def __init__(self,
        model:AutoEncoder, # Model
        dataloader:torch.utils.data.DataLoader, # Dataloader
        loss_func:torch.nn.modules.loss._Loss, # Loss function
        optimizer:torch.optim.Optimizer, # Optimizer
        n_epochs:int, # Number of training epochs
        device:str # Device
    ):
        self.model = model
        self.dataloader = dataloader
        self.loss_func = loss_func
        self.optimizer = optimizer
        self.n_epochs = n_epochs
        self.device = device

    def fit(self):
        # training loop
        for epoch in tqdm(range(self.n_epochs)):
            for batch_idx, (x,y) in enumerate(self.dataloader):
                x = x.to(self.device)
                self.optimizer.zero_grad()
                x_hat = self.model(x)
                loss = self.loss_func(x_hat, x)
                loss.backward()
                self.optimizer.step()
                if batch_idx % 100:
                    print('\r Train Epoch: {}/{} [{}/{} ({:.0f}%)]\tLoss: {:.6f}'.format(
                        epoch+1,
                        self.n_epochs,
                        batch_idx * len(x), 
                        len(self.dataloader.dataset),
                        100. * batch_idx / len(self.dataloader), 
                        loss.cpu().data.item()), 
                        end='')

