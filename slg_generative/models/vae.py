# AUTOGENERATED! DO NOT EDIT! File to edit: ../../nbs/01_models.vae.ipynb.

# %% auto 0
__all__ = ['SEED', 'AEEncoder', 'AEDecoder', 'AutoEncoder']

# %% ../../nbs/01_models.vae.ipynb 3
# from matplotlib import pyplot as plt
# import numpy as np
import torch
import torch.nn as nn
from ..data.datasets import FashionMnistDataset

# from torch.optim import Adam
# from tqdm import tqdm
# import torch.nn.functional as F
# from torch.utils.data import Dataset, DataLoader
# import ipdb
# import torchvision

SEED = 42
# np.random.seed(SEED)
torch.manual_seed(SEED)
torch.cuda.manual_seed(SEED)
torch.backends.cudnn.deterministic = True

# %% ../../nbs/01_models.vae.ipynb 5
class AEEncoder(nn.Module):
    "Simple AE Encoder"
    
    def __init__(self,
        input_dim:int=784, # Input dimension
        hidden_dim:int=512, # Hidden dimension
        latent_dim:int=2 # Latent dimension
        ):
        super().__init__()
        self.layer1 = nn.Linear(input_dim, hidden_dim)
        self.layer2 = nn.Linear(hidden_dim, latent_dim)        

    def forward(self,
        x:torch.FloatTensor # B x D
        )->torch.FloatTensor: # B xD
        seq = nn.Sequential(self.layer1, nn.ReLU(), self.layer2, nn.ReLU())
        z = seq(x)
        return z


# %% ../../nbs/01_models.vae.ipynb 7
class AEDecoder(nn.Module):
  "Decoder"
  
  def __init__(self,
    latent_dim=2, # Latent dimension
    hidden_dim=512, # Hidden dimension
    output_dim=784, # Output dimension
    ):
    super().__init__()
    self.layer1 = nn.Linear(latent_dim, hidden_dim)
    self.layer2 = nn.Linear(hidden_dim, output_dim)

  def forward(self,
    z:torch.Tensor # Latent variables
    )->torch.Tensor: # Image output
    seq = nn.Sequential(self.layer1, nn.ReLU(), self.layer2, nn.Sigmoid())
    x = seq(z)
    return(x)

# %% ../../nbs/01_models.vae.ipynb 9
class AutoEncoder(nn.Module):
  "autoencoder"

  def __init__(self,
    input_dim=784, # Output dimension
    hidden_dim=512, # Hidden dimension
    latent_dim=2, # Latent dimension
    ):
    super().__init__()
    self.encoder = AEEncoder(input_dim=input_dim, hidden_dim=hidden_dim,latent_dim=latent_dim)
    self.decoder = AEDecoder(latent_dim=latent_dim, hidden_dim=hidden_dim, output_dim=input_dim)
  
  def forward(self, x:torch.Tensor)->torch.Tensor:
    z = self.encoder(x)
    return self.decoder(z)
