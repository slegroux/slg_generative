[
  {
    "objectID": "vae.html",
    "href": "vae.html",
    "title": "Variational AutoEncoder Models",
    "section": "",
    "text": "FashionMnistDataset\n\n FashionMnistDataset (csv_file='~/Data/fashion-mnist/fashion-\n                      mnist_train.csv')\n\nFashion MNIST Dataset\n\nmap_labels = {\n  \"0\": \"T-shirt/top\", \"1\": \"Trouser\", \"2\": \"Pullover\", \"3\": \"Dress\",\n  \"4\": \"Coat\", \"5\": \"Sandal\", \"6\": \"Shirt\", \"7\": \"Sneaker\", \"8\": \"Bag\",\n  \"9\": \"Ankle boot\"\n}\n\nds = FashionMnistDataset()\ndl = torch.utils.data.DataLoader(ds, batch_size=128, shuffle=True)\n\nX, y = next(iter(dl))\nprint(X.type(), y.type())\n\nplt.figure(figsize = (1, 1))\nbatch_n = 0\nplt.imshow(X[batch_n].numpy().reshape(28,28),cmap='gray')\nplt.title(map_labels[str(int(y[batch_n]))])\nplt.show()\nprint(f\"shape of image batch: {X.shape}, Shape of labels: {y.shape}\")\n\ntorch.DoubleTensor torch.IntTensor\n\n\n\n\n\nshape of image batch: torch.Size([128, 784]), Shape of labels: torch.Size([128])\n\n\n\n\n\nEncoder\n\n Encoder (latent_dim=2)\n\nEncoder\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nlatent_dim\nint\n2\nLatent dimension\n\n\n\n\nprint(X.type())\ne = Encoder()\nee = e(X.type(torch.FloatTensor))\nprint(ee.shape, ee.type())\n\ntorch.DoubleTensor\ntorch.Size([128, 2]) torch.FloatTensor\n\n\n\n\n\nDecoder\n\n Decoder (latent_dim:int=2)\n\nDecoder\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nlatent_dim\nint\n2\nLatent dimension\n\n\n\n\n\n\nAutoEncoder\n\n AutoEncoder (latent_dim:int=2)\n\nautoencoder\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nlatent_dim\nint\n2\nLatent dimension"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Generative",
    "section": "",
    "text": "Looking at foundation of generative AI, starting with Variational AutoEncoders. More to come later!"
  },
  {
    "objectID": "index.html#install",
    "href": "index.html#install",
    "title": "Generative",
    "section": "Install",
    "text": "Install\npip install slg_generative"
  },
  {
    "objectID": "index.html#how-to-use",
    "href": "index.html#how-to-use",
    "title": "Generative",
    "section": "How to use",
    "text": "How to use\nSome example usage of the library\n\nData\n\nfrom slg_generative.data.datasets import FashionMnistDataset\nfrom torch.utils.data import DataLoader\n\nds = FashionMnistDataset(csv_file=\"~/Data/fashion-mnist/fashion-mnist_train.csv\")\ndl = DataLoader(ds,batch_size=128, shuffle=True, num_workers=0)\nval_ds = FashionMnistDataset(csv_file=\"~/Data/fashion-mnist/fashion-mnist_test.csv\")\nval_dl = DataLoader(val_ds,batch_size=128, shuffle=True, num_workers=0)\n\n\n\nModel\n\nimport torch\nfrom slg_generative.models.vae import AutoEncoder\n\ndevice = 'mps' if torch.backends.mps.is_available() else 'cpu' # or 'cuda' for nvidia gpus\nautoencoder = AutoEncoder().to(device)\n\n\n\nTraining Setup\n\nfrom torch.optim import Adam\nimport torch.nn as nn\n\nopt = Adam(autoencoder.parameters(), lr=1e-3)\nloss_func = nn.MSELoss()\nn_epochs = 5\n\n\n\nTraining Loop\n\nfrom slg_generative.training import Trainer\n\ntrainer = Trainer(autoencoder, dl, val_dl, loss_func, opt, n_epochs, device)\ntrainer.fit()\n\n  0%|          | 0/5 [00:00<?, ?it/s]\n\n\n Train Epoch: 1/5 [51072/60000 (85%)]   Loss: 0.622993\n\n\n 20%|██        | 1/5 [00:02<00:11,  2.91s/it]\n\n\n Validion Loss: 0.6280178548414496\n Train Epoch: 2/5 [51072/60000 (85%)]   Loss: 0.619879\n\n\n 40%|████      | 2/5 [00:05<00:08,  2.90s/it]\n\n\n Validion Loss: 0.6231143165238296\n Train Epoch: 3/5 [51072/60000 (85%)]   Loss: 0.620355\n\n\n 60%|██████    | 3/5 [00:08<00:05,  2.99s/it]\n\n\n Validion Loss: 0.621142838574663\n Train Epoch: 4/5 [51072/60000 (85%)]   Loss: 0.603328\n\n\n 80%|████████  | 4/5 [00:13<00:03,  3.55s/it]\n\n\n Validion Loss: 0.6198473678359503\n Train Epoch: 5/5 [51072/60000 (85%)]   Loss: 0.631183\n\n\n100%|██████████| 5/5 [00:16<00:00,  3.40s/it]\n\n\n Validion Loss: 0.6195422592042368"
  },
  {
    "objectID": "models.vae.html",
    "href": "models.vae.html",
    "title": "VAE Model",
    "section": "",
    "text": "source\n\nAEEncoder\n\n AEEncoder (input_dim:int=784, hidden_dim:int=512, latent_dim:int=2)\n\nSimple AE Encoder\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\ninput_dim\nint\n784\nInput dimension\n\n\nhidden_dim\nint\n512\nHidden dimension\n\n\nlatent_dim\nint\n2\nLatent dimension\n\n\n\n\nds = FashionMnistDataset(\"~/Data/fashion-mnist/fashion-mnist_train.csv\")\ndl = torch.utils.data.DataLoader(ds, batch_size=128, shuffle=True)\nX, y = next(iter(dl))\ne = AEEncoder(input_dim=784, hidden_dim=512, latent_dim=2)\nee = e(X)\nprint(f\"latent output shape {ee.shape}, {ee.type()}\")\n\nlatent output shape torch.Size([128, 2]), torch.FloatTensor\n\n\n\nsource\n\n\nAEDecoder\n\n AEDecoder (latent_dim=2, hidden_dim=512, output_dim=784)\n\nDecoder\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nlatent_dim\nint\n2\nLatent dimension\n\n\nhidden_dim\nint\n512\nHidden dimension\n\n\noutput_dim\nint\n784\nOutput dimension\n\n\n\n\nd = AEDecoder(latent_dim=2, hidden_dim=512, output_dim=784)\ndd = d(ee)\nprint(dd.shape)\n\ntorch.Size([128, 784])\n\n\n\nsource\n\n\nAutoEncoder\n\n AutoEncoder (input_dim=784, hidden_dim=512, latent_dim=2)\n\nautoencoder\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\ninput_dim\nint\n784\nOutput dimension\n\n\nhidden_dim\nint\n512\nHidden dimension\n\n\nlatent_dim\nint\n2\nLatent dimension\n\n\n\n\nae = AutoEncoder(input_dim=784, hidden_dim=512, latent_dim=2)\nout = ae(X)\nprint(out.shape)\n\ntorch.Size([128, 784])"
  },
  {
    "objectID": "data.datasets.html",
    "href": "data.datasets.html",
    "title": "Datasets",
    "section": "",
    "text": "source\n\nImageDataset\n\n ImageDataset ()\n\nBase class for image datasets providing visualization of (image, label) samples\n\nsource\n\n\nMnistDataset\n\n MnistDataset (data_root:str='./data')\n\nMNIST digit dataset\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\ndata_root\nstr\n./data\nPath to data root folder\n\n\n\n\nds = MnistDataset('~/Data')\nprint(f\"Number of samples in the dataset: {len(ds)}\")\nX,y = ds[0]\nprint(f\"Shape of image: {X.shape}, corresponding digit: {int(y)}\")\nprint(f\"types: {X.type()}, {y.type()}\")\n\nds.show(0)\n\nNumber of samples in the dataset: 60000\nShape of image: torch.Size([784]), corresponding digit: 5\ntypes: torch.FloatTensor, torch.LongTensor\n\n\n\n\n\n\nsource\n\n\nFashionMnistDataset\n\n FashionMnistDataset (csv_file:str)\n\nFashion MNIST Dataset\n\n\n\n\nType\nDetails\n\n\n\n\ncsv_file\nstr\nPath to csv data file\n\n\n\n\nmap_labels = {\n  \"0\": \"T-shirt/top\", \"1\": \"Trouser\", \"2\": \"Pullover\", \"3\": \"Dress\",\n  \"4\": \"Coat\", \"5\": \"Sandal\", \"6\": \"Shirt\", \"7\": \"Sneaker\", \"8\": \"Bag\",\n  \"9\": \"Ankle boot\"\n}\n\nds = FashionMnistDataset(csv_file=\"~/Data/fashion-mnist/fashion-mnist_train.csv\")\nprint(f\"Number of samples in the dataset: {len(ds)}\")\nX,y = ds[0]\n\nprint(f\"Shape of image: {X.shape}, corresponding label: {map_labels[str(int(y))]}\")\nds.show(0)\n\ndl = torch.utils.data.DataLoader(ds, batch_size=128, shuffle=True)\n\nX, y = next(iter(dl))\nprint(f\"types of batch content: {X.type()}, {y.type()}\")\n\nNumber of samples in the dataset: 60000\nShape of image: torch.Size([784]), corresponding label: Pullover\n\n\n\n\n\ntypes of batch content: torch.FloatTensor, torch.LongTensor"
  },
  {
    "objectID": "training.html",
    "href": "training.html",
    "title": "Training",
    "section": "",
    "text": "source\n\nTrainer\n\n Trainer (model:slg_generative.models.vae.AutoEncoder,\n          train_dataloader:torch.utils.data.dataloader.DataLoader,\n          validation_dataloader:torch.utils.data.dataloader.DataLoader,\n          loss_func:torch.nn.modules.loss._Loss,\n          optimizer:torch.optim.optimizer.Optimizer, n_epochs:int,\n          device:str)\n\nTrainer for VAE models\n\n\n\n\nType\nDetails\n\n\n\n\nmodel\nAutoEncoder\nModel\n\n\ntrain_dataloader\nDataLoader\nTrain Dataloader\n\n\nvalidation_dataloader\nDataLoader\nValidation Dataloader\n\n\nloss_func\n_Loss\nLoss function\n\n\noptimizer\nOptimizer\nOptimizer\n\n\nn_epochs\nint\nNumber of training epochs\n\n\ndevice\nstr\nDevice\n\n\n\n\n# device\ndevice = 'mps' if torch.backends.mps.is_available() else 'cpu' # or 'cuda' for nvidia gpus\n\n# data\ntrain_ds = FashionMnistDataset(csv_file=\"~/Data/fashion-mnist/fashion-mnist_train.csv\")\ntrain_dl = torch.utils.data.DataLoader(train_ds, batch_size=128, shuffle=True)\ntest_ds = FashionMnistDataset(csv_file=\"~/Data/fashion-mnist/fashion-mnist_test.csv\")\ntest_dl = torch.utils.data.DataLoader(test_ds, batch_size=128, shuffle=True)\n# model\nautoencoder = AutoEncoder().to(device)\n# training params\nn_epochs = 5\n# optim\nopt = Adam(autoencoder.parameters(), lr=1e-3)\n# # mean square error loss \nloss_func = nn.MSELoss()\n\n\ntrainer = Trainer(autoencoder, train_dl, test_dl, loss_func, opt, n_epochs, device)\ntrainer.fit()\n\n  0%|          | 0/20 [00:00<?, ?it/s]\n\n\n Train Epoch: 1/20 [51072/60000 (85%)]  Loss: 0.608026\n\n\n  5%|▌         | 1/20 [00:02<00:52,  2.75s/it]\n\n\n Validion Loss: 0.6283872451963304\n Train Epoch: 2/20 [51072/60000 (85%)]  Loss: 0.634786\n\n\n 10%|█         | 2/20 [00:05<00:49,  2.77s/it]\n\n\n Validion Loss: 0.6230814268317404\n Train Epoch: 3/20 [51072/60000 (85%)]  Loss: 0.613410\n\n\n 15%|█▌        | 3/20 [00:08<00:47,  2.77s/it]\n\n\n Validion Loss: 0.621926503845408\n Train Epoch: 4/20 [51072/60000 (85%)]  Loss: 0.614229\n\n\n 20%|██        | 4/20 [00:11<00:49,  3.07s/it]\n\n\n Validion Loss: 0.6203305706193175\n Train Epoch: 5/20 [51072/60000 (85%)]  Loss: 0.615765\n\n\n 25%|██▌       | 5/20 [00:15<00:48,  3.25s/it]\n\n\n Validion Loss: 0.6193617265435714\n Train Epoch: 6/20 [51072/60000 (85%)]  Loss: 0.622439\n\n\n 30%|███       | 6/20 [00:18<00:44,  3.18s/it]\n\n\n Validion Loss: 0.6182164255576797\n Train Epoch: 7/20 [51072/60000 (85%)]  Loss: 0.614843\n\n\n 35%|███▌      | 7/20 [00:21<00:40,  3.13s/it]\n\n\n Validion Loss: 0.6183422615256491\n Train Epoch: 8/20 [51072/60000 (85%)]  Loss: 0.626013\n\n\n 40%|████      | 8/20 [00:24<00:37,  3.10s/it]\n\n\n Validion Loss: 0.6176317915131774\n Train Epoch: 9/20 [51072/60000 (85%)]  Loss: 0.611943\n\n\n 45%|████▌     | 9/20 [00:27<00:34,  3.18s/it]\n\n\n Validion Loss: 0.6173656914807573\n Train Epoch: 10/20 [51072/60000 (85%)] Loss: 0.591853\n\n\n 50%|█████     | 10/20 [00:30<00:31,  3.15s/it]\n\n\n Validion Loss: 0.6174960664555996\n Train Epoch: 11/20 [51072/60000 (85%)] Loss: 0.594108\n\n\n 55%|█████▌    | 11/20 [00:34<00:28,  3.15s/it]\n\n\n Validion Loss: 0.6168823046020314\n Train Epoch: 12/20 [51072/60000 (85%)] Loss: 0.623872\n\n\n 60%|██████    | 12/20 [00:37<00:25,  3.16s/it]\n\n\n Validion Loss: 0.6161797476720207\n Train Epoch: 13/20 [51072/60000 (85%)] Loss: 0.622144\n\n\n 65%|██████▌   | 13/20 [00:40<00:22,  3.18s/it]\n\n\n Validion Loss: 0.6147392731678637\n Train Epoch: 14/20 [51072/60000 (85%)] Loss: 0.635082\n\n\n 70%|███████   | 14/20 [00:43<00:19,  3.17s/it]\n\n\n Validion Loss: 0.6154736770859247\n Train Epoch: 15/20 [51072/60000 (85%)] Loss: 0.627957\n\n\n 75%|███████▌  | 15/20 [00:46<00:16,  3.22s/it]\n\n\n Validion Loss: 0.6160034620309178\n Train Epoch: 16/20 [51072/60000 (85%)] Loss: 0.595614\n\n\n 80%|████████  | 16/20 [00:50<00:12,  3.19s/it]\n\n\n Validion Loss: 0.6154555444475971\n Train Epoch: 17/20 [51072/60000 (85%)] Loss: 0.615244\n\n\n 85%|████████▌ | 17/20 [00:53<00:09,  3.16s/it]\n\n\n Validion Loss: 0.6151369795014586\n Train Epoch: 18/20 [51072/60000 (85%)] Loss: 0.610300\n\n\n 90%|█████████ | 18/20 [00:56<00:06,  3.14s/it]\n\n\n Validion Loss: 0.6152783307848098\n Train Epoch: 19/20 [51072/60000 (85%)] Loss: 0.612640\n\n\n 95%|█████████▌| 19/20 [00:59<00:03,  3.16s/it]\n\n\n Validion Loss: 0.6153503105610232\n Train Epoch: 20/20 [51072/60000 (85%)] Loss: 0.601384\n\n\n100%|██████████| 20/20 [01:02<00:00,  3.13s/it]\n\n\n Validion Loss: 0.6152682040311113\n\n\n\n\n\n\nPATH = \"runs/20221202_000258/model_19\"\ndevice = torch.device('cpu')\nmodel = AutoEncoder()\nmodel.load_state_dict(torch.load(PATH, map_location=device))\n\n<All keys matched successfully>"
  }
]